{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89145820",
   "metadata": {},
   "source": [
    "# EDA Code for Temporal Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fb40d",
   "metadata": {},
   "source": [
    "Import all libraries used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79903271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60367812",
   "metadata": {},
   "source": [
    "Set plot style for <code>matplotlib</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9713a9",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b375812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_annual(series):\n",
    "    annual = seasonal_decompose(series, model='additive', period=8760)\n",
    "    return pd.DataFrame({'Observed' : annual.observed, 'Trend' : annual.trend, \n",
    "                         'Seasonal': annual.seasonal, 'Residual' : annual.resid})\n",
    "    \n",
    "def decompose_daily(series):\n",
    "    daily = seasonal_decompose(series, model='additive', period = 24)\n",
    "    return pd.DataFrame({'Observed' : daily.observed, 'Trend' : daily.trend, \n",
    "                         'Seasonal': daily.seasonal, 'Residual' : daily.resid})\n",
    "\n",
    "def decompose_useful(df):\n",
    "    \"\"\"\n",
    "    Takes in the data for a station and adds the columns I found were useful.\n",
    "    \"\"\"\n",
    "    df1 = add_saturation_vapor_pressure(df)\n",
    "    temp_decomp_annual = seasonal_decompose(df['TEMP'], model='additive', period=8760)\n",
    "    temp_decomp_daily = seasonal_decompose(df['TEMP'], model='additive', period=24)\n",
    "    vapor_pressure_decomp_annual = seasonal_decompose(df1['VAPOR_PRESSURE'], model='additive', period=8760)\n",
    "\n",
    "    df1['temp_annual_trend'] = temp_decomp_annual.trend\n",
    "    df1['temp_annual_seasonal'] = temp_decomp_annual.seasonal\n",
    "    df1['temp_annual_resid'] = temp_decomp_annual.resid\n",
    "    df1['temp_daily_trend'] = temp_decomp_daily.trend\n",
    "    df1['temp_daily_seasonal'] = temp_decomp_daily.seasonal\n",
    "    df1['temp_daily_resid'] = temp_decomp_daily.resid\n",
    "    df1['vapor_pressure_annual_trend'] = vapor_pressure_decomp_annual.trend\n",
    "    df1['vapor_pressure_annual_seasonal'] = vapor_pressure_decomp_annual.seasonal\n",
    "    df1['vapor_pressure_annual_resid'] = vapor_pressure_decomp_annual.resid\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb15acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_residual_annual(series):\n",
    "    \"\"\"\n",
    "    Takes a series, runs time series decomposition over an annual period, and returns a series with the residuals.\n",
    "    Requires statsmodels.tsa.seasonal\n",
    "    \"\"\"\n",
    "    return seasonal_decompose(series, model='additive', period=8760).resid\n",
    "\n",
    "def decompose_residual_daily(series):\n",
    "    \"\"\"\n",
    "    Takes a series, runs time series decomposition over a daily period, and returns a series with the residuals.\n",
    "    Requires statsmodels.tsa.seasonal\n",
    "    \"\"\"\n",
    "    return seasonal_decompose(series, model='additive', period=24).resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa0590",
   "metadata": {},
   "source": [
    "Perform all time series decompositions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f092d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing your CSV files\n",
    "folder_path = '../weather/processed'\n",
    "\n",
    "# Dictionary to store decomposition results for each file\n",
    "decomposition_total_results_precip_amount = {}\n",
    "decomposition_winter_2023_results_precip_amount = {}\n",
    "decomposition_total_results_temp = {}\n",
    "decomposition_winter_2023_results_temp = {}\n",
    "decomposition_total_results_relative_humidity = {}\n",
    "decomposition_winter_2023_results_relative_humidity = {}\n",
    "decomposition_total_results_station_pressure = {}\n",
    "decomposition_winter_2023_results_station_pressure = {}\n",
    "decomposition_total_results_wind_speed = {}\n",
    "decomposition_winter_2023_results_wind_speed = {}\n",
    "decomposition_total_results_vapor_pressure = {}\n",
    "decomposition_winter_2023_results_vapor_pressure = {}\n",
    "\n",
    "start_date_winter_2023 = '2023-01-01'\n",
    "end_date_winter_2023 = '2023-03-31'\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        data = pd.read_csv(file_path, parse_dates=['UTC_DATE'], index_col='UTC_DATE')\n",
    "\n",
    "        subset = data[(data.index >= start_date_winter_2023) & (data.index <= end_date_winter_2023)]\n",
    "        \n",
    "        # Perform time series decomposition - precip_amount\n",
    "        result_precip_amount = seasonal_decompose(data['PRECIP_AMOUNT'], model='additive', period=8760)\n",
    "        result_winter_2023_precip_amount = seasonal_decompose(subset['PRECIP_AMOUNT'], model='additive', period=24)\n",
    "        \n",
    "        # Store the decomposition result in the dictionary - precip_amount\n",
    "        decomposition_total_results_precip_amount[file_name] = result_precip_amount\n",
    "        decomposition_winter_2023_results_precip_amount[file_name] = result_winter_2023_precip_amount\n",
    "        \n",
    "        # Perform time series decomposition - temp\n",
    "        result_temp = seasonal_decompose(data['TEMP'], model='additive', period=8760)\n",
    "        result_winter_2023_temp = seasonal_decompose(subset['TEMP'], model='additive', period=24)\n",
    "        \n",
    "        # Store the decomposition result in the dictionary - temp\n",
    "        decomposition_total_results_temp[file_name] = result_temp\n",
    "        decomposition_winter_2023_results_temp[file_name] = result_winter_2023_temp\n",
    "        \n",
    "        # Perform time series decomposition - RELATIVE_HUMIDITY\n",
    "        result_relative_humidity = seasonal_decompose(data['RELATIVE_HUMIDITY'], model='additive', period=8760)\n",
    "        result_winter_2023_relative_humidity = seasonal_decompose(subset['RELATIVE_HUMIDITY'], model='additive', period = 24)\n",
    "        \n",
    "        # Store the decomposition result in the dictionary - RELATIVE_HUMIDITY\n",
    "        decomposition_total_results_relative_humidity[file_name] = result_relative_humidity\n",
    "        decomposition_winter_2023_results_relative_humidity[file_name] = result_winter_2023_relative_humidity\n",
    "        \n",
    "        # Perform time series decomposition - STATION_PRESSURE\n",
    "        result_station_pressure = seasonal_decompose(data['STATION_PRESSURE'], model='additive', period=8760)\n",
    "        result_winter_2023_station_pressure = seasonal_decompose(subset['STATION_PRESSURE'], model='additive', period = 24)\n",
    "        \n",
    "        # Store the decomposition result in the dictionary - STATION_PRESSURE\n",
    "        decomposition_total_results_station_pressure[file_name] = result_station_pressure\n",
    "        decomposition_winter_2023_results_station_pressure[file_name] = result_winter_2023_station_pressure\n",
    "        \n",
    "        # Perform time series decomposition - WIND_SPEED\n",
    "        result_wind_speed = seasonal_decompose(data['WIND_SPEED'], model='additive', period=8760)\n",
    "        result_winter_2023_wind_speed = seasonal_decompose(subset['WIND_SPEED'], model='additive', period=24)\n",
    "        \n",
    "        # Store the decomposition result in the dictionary - WIND_SPEED\n",
    "        decomposition_total_results_wind_speed[file_name] = result_wind_speed\n",
    "        decomposition_winter_2023_results_wind_speed[file_name] = result_winter_2023_wind_speed\n",
    "        \n",
    "        # Perform time series decomposition - VAPOR_PRESSURE\n",
    "        result_vapor_pressure = seasonal_decompose(data['VAPOR_PRESSURE'], model='additive', period=8760)\n",
    "        result_winter_2023_vapor_pressure = seasonal_decompose(subset['VAPOR_PRESSURE'], model='additive', period=24)\n",
    "        \n",
    "        # Store the decomposition result in the dictionary - VAPOR_PRESSURE\n",
    "        decomposition_total_results_vapor_pressure[file_name] = result_vapor_pressure\n",
    "        decomposition_winter_2023_results_vapor_pressure[file_name] = result_winter_2023_vapor_pressure\n",
    "        \n",
    "file_name_keys = list(decomposition_total_results_precip_amount.keys())\n",
    "\n",
    "# # Save the decomposition results to files (Optional)\n",
    "# for file_name, result in decomposition_results.items():\n",
    "#    output_file = f\"decomposition_{file_name}.json\"  # Change the file format as needed\n",
    "#    result.save(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe14b6",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43684255",
   "metadata": {},
   "source": [
    "The following cell is an example time-series decomposition. This is multi-year temperature data for BARRIE-ORO, with a seasonality period of 8760 hours or 365 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4848ac",
   "metadata": {},
   "source": [
    "### Decomposed Temperature Data, Annual Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eba36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_total_results_temp[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(8, 10), dpi=300)\n",
    "result.observed.plot(ax=ax1, lw=1)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=1)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=1)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=1)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../../images/decomp_day_temp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0bec05",
   "metadata": {},
   "source": [
    "### Decomposed Temperature Data, Daily Period, Winter 2023\n",
    "\n",
    "The following cell is another example time-series decomposition. This is temperature data for OSHAWA over the first quarter of 2023, with a seasonality period of 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affe4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_winter_2023_results_temp[file_name_keys[5]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 10))\n",
    "result.observed.plot(ax=ax1, lw=1.5)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=1.5)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=1.5)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=1.5)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc70d1d",
   "metadata": {},
   "source": [
    "The following lists for all stations their lowest correlation coefficient when compared to other stations for observed temperature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have multiple trend components stored in a list or dictionary\n",
    "# For example, trend_components = [result1.trend, result2.trend, result3.trend]\n",
    "trend_components = [decomposition_total_results_temp[x].observed.dropna() for x in decomposition_total_results_temp]\n",
    "\n",
    "# Create an empty correlation matrix\n",
    "num_trends = len(trend_components)\n",
    "correlation_matrix = np.zeros((num_trends, num_trends))\n",
    "\n",
    "# Calculate correlation coefficients pairwise\n",
    "for i in range(num_trends):\n",
    "    for j in range(num_trends):\n",
    "        # Ensure both series have the same length (trim if needed)\n",
    "        min_length = min(len(trend_components[i]), len(trend_components[j]))\n",
    "        trend1 = trend_components[i][:min_length]\n",
    "        trend2 = trend_components[j][:min_length]\n",
    "\n",
    "        # Calculate correlation coefficient between the two trend components\n",
    "        correlation_coefficient = np.corrcoef(trend1, trend2)[0, 1]\n",
    "        correlation_matrix[i, j] = correlation_coefficient\n",
    "\n",
    "# Display the correlation matrix\n",
    "#print(\"Correlation matrix between trend components:\")\n",
    "#print(correlation_matrix)\n",
    "\n",
    "min_correlations = np.min(correlation_matrix, axis=1)\n",
    "\n",
    "# Display the list of minimum correlation coefficients\n",
    "print(\"Minimum correlation coefficient for each observed component:\")\n",
    "print(min_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673162d4",
   "metadata": {},
   "source": [
    "In comparison to the above, the following lists for all stations their lowest correlation coefficient when compared to other stations for the trend component of the temperature data decomposition are seemingly much lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf339b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming you have multiple trend components stored in a list or dictionary\n",
    "# For example, trend_components = [result1.trend, result2.trend, result3.trend]\n",
    "trend_components = [decomposition_total_results_temp[x].trend.dropna() for x in decomposition_total_results_temp]\n",
    "\n",
    "# Create an empty correlation matrix\n",
    "num_trends = len(trend_components)\n",
    "correlation_matrix = np.zeros((num_trends, num_trends))\n",
    "\n",
    "# Calculate correlation coefficients pairwise\n",
    "for i in range(num_trends):\n",
    "    for j in range(num_trends):\n",
    "        # Ensure both series have the same length (trim if needed)\n",
    "        min_length = min(len(trend_components[i]), len(trend_components[j]))\n",
    "        trend1 = trend_components[i][:min_length]\n",
    "        trend2 = trend_components[j][:min_length]\n",
    "\n",
    "        # Calculate correlation coefficient between the two trend components\n",
    "        correlation_coefficient = np.corrcoef(trend1, trend2)[0, 1]\n",
    "        correlation_matrix[i, j] = correlation_coefficient\n",
    "\n",
    "# Display the correlation matrix\n",
    "#print(\"Correlation matrix between trend components:\")\n",
    "#print(correlation_matrix)\n",
    "\n",
    "min_correlations = np.min(correlation_matrix, axis=1)\n",
    "\n",
    "# Display the list of minimum correlation coefficients\n",
    "print(\"Minimum correlation coefficient for each trend component:\")\n",
    "print(min_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c83b9",
   "metadata": {},
   "source": [
    "And we do the same for the seasonal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4186c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have multiple trend components stored in a list or dictionary\n",
    "# For example, trend_components = [result1.trend, result2.trend, result3.trend]\n",
    "trend_components = [decomposition_total_results_temp[x].seasonal.dropna() for x in decomposition_total_results_temp]\n",
    "\n",
    "# Create an empty correlation matrix\n",
    "num_trends = len(trend_components)\n",
    "correlation_matrix = np.zeros((num_trends, num_trends))\n",
    "\n",
    "# Calculate correlation coefficients pairwise\n",
    "for i in range(num_trends):\n",
    "    for j in range(num_trends):\n",
    "        # Ensure both series have the same length (trim if needed)\n",
    "        min_length = min(len(trend_components[i]), len(trend_components[j]))\n",
    "        trend1 = trend_components[i][:min_length]\n",
    "        trend2 = trend_components[j][:min_length]\n",
    "\n",
    "        # Calculate correlation coefficient between the two trend components\n",
    "        correlation_coefficient = np.corrcoef(trend1, trend2)[0, 1]\n",
    "        correlation_matrix[i, j] = correlation_coefficient\n",
    "\n",
    "# Display the correlation matrix\n",
    "#print(\"Correlation matrix between trend components:\")\n",
    "#print(correlation_matrix)\n",
    "\n",
    "min_correlations = np.min(correlation_matrix, axis=1)\n",
    "\n",
    "# Display the list of minimum correlation coefficients\n",
    "print(\"Minimum correlation coefficient for each seasonal component:\")\n",
    "print(min_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7caae",
   "metadata": {},
   "source": [
    "Finally, we do the same for the residual component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54960e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have multiple trend components stored in a list or dictionary\n",
    "# For example, trend_components = [result1.trend, result2.trend, result3.trend]\n",
    "trend_components = [decomposition_total_results_temp[x].resid.dropna() for x in decomposition_total_results_temp]\n",
    "\n",
    "# Create an empty correlation matrix\n",
    "num_trends = len(trend_components)\n",
    "correlation_matrix = np.zeros((num_trends, num_trends))\n",
    "\n",
    "# Calculate correlation coefficients pairwise\n",
    "for i in range(num_trends):\n",
    "    for j in range(num_trends):\n",
    "        # Ensure both series have the same length (trim if needed)\n",
    "        min_length = min(len(trend_components[i]), len(trend_components[j]))\n",
    "        trend1 = trend_components[i][:min_length]\n",
    "        trend2 = trend_components[j][:min_length]\n",
    "\n",
    "        # Calculate correlation coefficient between the two trend components\n",
    "        correlation_coefficient = np.corrcoef(trend1, trend2)[0, 1]\n",
    "        correlation_matrix[i, j] = correlation_coefficient\n",
    "\n",
    "# Display the correlation matrix\n",
    "#print(\"Correlation matrix between trend components:\")\n",
    "#print(correlation_matrix)\n",
    "\n",
    "min_correlations = np.min(correlation_matrix, axis=1)\n",
    "\n",
    "# Display the list of minimum correlation coefficients\n",
    "print(\"Minimum correlation coefficient for each resid component:\")\n",
    "print(min_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a19772",
   "metadata": {},
   "source": [
    "Visualized below are the trend components. Notice the clear correlation between the trend components!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming trend_components_dict is a dictionary containing trend components\n",
    "# For example: trend_components_dict = {'Decomposition 1': result1.trend, 'Decomposition 2': result2.trend}\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "\n",
    "# Plot each trend component from the dictionary with its corresponding label\n",
    "for label, decomped in decomposition_total_results_temp.items():\n",
    "    label = label[:-4]\n",
    "    plt.plot(decomped.trend.dropna(), label=label, lw=1.5)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.ylim(1, 12)\n",
    "plt.title('Comparison of Trend Components for Temperature')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature (Â°C)')\n",
    "plt.legend(loc ='lower right')\n",
    "plt.savefig('../../../images/temp_trend_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee87fc",
   "metadata": {},
   "source": [
    "## Exploratory\n",
    "\n",
    "Everything below is experimental."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b235b01",
   "metadata": {},
   "source": [
    "### Vapor Pressure Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a0504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_total_results_vapor_pressure[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=0.7)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=0.7)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=0.7)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=0.7)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d6b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_winter_2023_results_vapor_pressure[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=1.5)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=1.5)\n",
    "#result.trend.to_csv('trend.csv')\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=1.5)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=1.5)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a04865",
   "metadata": {},
   "source": [
    "### Relative Humidity Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bdea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_total_results_relative_humidity[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=0.7)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=0.7)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=0.7)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=0.7)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_winter_2023_results_relative_humidity[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=1.5)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=1.5)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=1.5)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=1.5)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b38c05",
   "metadata": {},
   "source": [
    "### Precip Amount Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeebe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_total_results_precip_amount[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=0.7)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=0.7)\n",
    "#result.trend.to_csv('trend.csv')\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=0.7)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=0.7)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../../../images/decomp_year_precip.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_winter_2023_results_precip_amount[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=1.5)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=1.5)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=1.5)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=1.5)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../../../images/decomp_day_precip.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693a65f",
   "metadata": {},
   "source": [
    "### Station Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_total_results_station_pressure[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=0.7)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=0.7)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=0.7)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=0.7)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80870296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_winter_2023_results_station_pressure[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=1.5)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=1.5)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=1.5)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=1.5)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc0a85",
   "metadata": {},
   "source": [
    "### Wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ff71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_total_results_wind_speed[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=0.7)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=0.7)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=0.7)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=0.7)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60277f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposed components\n",
    "result = decomposition_winter_2023_results_wind_speed[file_name_keys[0]]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))\n",
    "result.observed.plot(ax=ax1, lw=1.5)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "result.trend.plot(ax=ax2, lw=1.5)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "result.seasonal.plot(ax=ax3, lw=1.5)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "result.resid.plot(ax=ax4, lw=1.5)\n",
    "ax4.set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedff23",
   "metadata": {},
   "source": [
    "## Autocorrelation Analysis\n",
    "\n",
    "Based on the above cells, the only ones that are really worth decomposing are temp and potentially RH and vapor pressure. Let's try to run autocorrelation analysis on temp, RH and vapor pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_autocorr = {}\n",
    "winter_2023_data_autocorr = {}\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        data = pd.read_csv(file_path, parse_dates=['UTC_DATE'], index_col='UTC_DATE')\n",
    "       \n",
    "        subset = data[(data.index >= start_date_winter_2023) & (data.index <= end_date_winter_2023)]\n",
    "        total_data_autocorr[file_name] = data\n",
    "        winter_2023_data_autocorr[file_name] = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute autocorrelation using Pandas' autocorr function\n",
    "autocorr_values = total_data_autocorr['BARRIE-ORO.csv']['TEMP'].autocorr(lag=8760)\n",
    "\n",
    "# Visualize autocorrelation function\n",
    "plt.figure(figsize=(10, 6))\n",
    "pd.plotting.autocorrelation_plot(total_data_autocorr['BARRIE-ORO.csv']['TEMP'])\n",
    "plt.title('Autocorrelation of Temperature Data, Annual Period')\n",
    "plt.xlabel('Lag (Hours/Days/Months)')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute autocorrelation using Pandas' autocorr function\n",
    "autocorr_values = winter_2023_data_autocorr['BARRIE-ORO.csv']['TEMP'].autocorr(lag=24)\n",
    "\n",
    "# Visualize autocorrelation function\n",
    "plt.figure(figsize=(10, 6))\n",
    "pd.plotting.autocorrelation_plot(winter_2023_data_autocorr['BARRIE-ORO.csv']['TEMP'])\n",
    "plt.title('Autocorrelation of Temperature Data, Daily Period')\n",
    "plt.xlabel('Lag (Hours/Days/Months)')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute autocorrelation using Pandas' autocorr function\n",
    "autocorr_values = total_data_autocorr['BARRIE-ORO.csv']['RELATIVE_HUMIDITY'].autocorr(lag=8760)\n",
    "\n",
    "# Visualize autocorrelation function\n",
    "plt.figure(figsize=(10, 6))\n",
    "pd.plotting.autocorrelation_plot(total_data_autocorr['BARRIE-ORO.csv']['RELATIVE_HUMIDITY'])\n",
    "plt.title('Autocorrelation of RH Data, Annual Period')\n",
    "plt.xlabel('Lag (Hours/Days/Months)')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ed24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute autocorrelation using Pandas' autocorr function\n",
    "autocorr_values = total_data_autocorr['BARRIE-ORO.csv']['VAPOR_PRESSURE'].autocorr(lag=8760)\n",
    "\n",
    "# Visualize autocorrelation function\n",
    "plt.figure(figsize=(10, 6), dpi=300)\n",
    "pd.plotting.autocorrelation_plot(total_data_autocorr['BARRIE-ORO.csv']['VAPOR_PRESSURE'])\n",
    "plt.title('Autocorrelation of Vapor Pressure Data, Annual Period')\n",
    "plt.xlabel('Lag (Hours)')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../../images/autocorr_vap_pressure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute autocorrelation using Pandas' autocorr function\n",
    "autocorr_values = winter_2023_data_autocorr['BARRIE-ORO.csv']['VAPOR_PRESSURE'].autocorr(lag=24)\n",
    "\n",
    "# Visualize autocorrelation function\n",
    "plt.figure(figsize=(10, 6))\n",
    "pd.plotting.autocorrelation_plot(winter_2023_data_autocorr['BARRIE-ORO.csv']['VAPOR_PRESSURE'])\n",
    "plt.title('Autocorrelation of Vapor Pressure Data, Daily Period For Fun')\n",
    "plt.xlabel('Lag (Hours/Days/Months)')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc8d67b",
   "metadata": {},
   "source": [
    "## Working with Lagged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40810941",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_lag = {}\n",
    "winter_2023_data_lag = {}\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        data = pd.read_csv(file_path, parse_dates=['UTC_DATE'], index_col='UTC_DATE')\n",
    "        subset = data[(data.index >= start_date_winter_2023) & (data.index <= end_date_winter_2023)]\n",
    "        total_data_lag[file_name] = data\n",
    "        winter_2023_data_lag[file_name] = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag the water vapor data by a specified number of time steps (e.g., 1 time step)\n",
    "lag = 1\n",
    "total_data_lag['BARRIE-ORO.csv']['VAPOR_PRESSURE_LAGGED'] = total_data_lag['BARRIE-ORO.csv']['VAPOR_PRESSURE'].shift(lag)\n",
    "#print(total_data_lag['BARRIE-ORO.csv'])\n",
    "\n",
    "# Remove NaN values resulting from the lag operation\n",
    "total_data_lag['BARRIE-ORO.csv'].dropna(inplace=True)\n",
    "\n",
    "# Calculate Pearson correlation coefficient between lagged water vapor and precipitation\n",
    "correlation = np.corrcoef(total_data_lag['BARRIE-ORO.csv']['PRECIP_AMOUNT'], total_data_lag['BARRIE-ORO.csv']['VAPOR_PRESSURE_LAGGED'])[0, 1]\n",
    "\n",
    "print(f\"Pearson's Correlation Coefficient Lagged: {correlation}\")\n",
    "\n",
    "# Calculate Pearson correlation coefficient between lagged water vapor and precipitation\n",
    "correlation = np.corrcoef(total_data_lag['BARRIE-ORO.csv']['PRECIP_AMOUNT'], total_data_lag['BARRIE-ORO.csv']['VAPOR_PRESSURE'])[0, 1]\n",
    "\n",
    "print(f\"Pearson's Correlation Coefficient Not Lagged: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcec245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag the water vapor data by a specified number of time steps (e.g., 1 time step)\n",
    "lag = -1\n",
    "working = total_data_lag['OSHAWA.csv']\n",
    "working['PRECIP_AMOUNT_LAGGED'] = working['PRECIP_AMOUNT'].shift(lag)\n",
    "\n",
    "# Remove NaN values resulting from the lag operation\n",
    "working.dropna(inplace=True)\n",
    "\n",
    "merged_data = pd.merge(working[['PRECIP_AMOUNT_LAGGED']], total_data_lag['TORONTO CITY.csv'][['PRECIP_AMOUNT']], left_index=True, right_index=True)\n",
    "\n",
    "# Calculate Pearson correlation coefficient between lagged water vapor and precipitation\n",
    "correlation = np.corrcoef(merged_data['PRECIP_AMOUNT_LAGGED'], merged_data['PRECIP_AMOUNT'])[0, 1]\n",
    "\n",
    "print(f\"Pearson's Correlation Coefficient: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab52e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag the wind direction data by a specified number of time steps (e.g., 1 time step)\n",
    "lag = 1\n",
    "total_data_lag['BARRIE-ORO.csv']['WIND_DIRECTION_LAGGED'] = data['WIND_DIRECTION'].shift(lag) * 10\n",
    "\n",
    "# Remove NaN values resulting from the lag operation\n",
    "total_data_lag['BARRIE-ORO.csv'].dropna(inplace=True)\n",
    "\n",
    "# Calculate circular correlation manually using trigonometric functions\n",
    "direction_rad = np.deg2rad(total_data_lag['BARRIE-ORO.csv']['WIND_DIRECTION'])\n",
    "lagged_direction_rad = np.deg2rad(total_data_lag['BARRIE-ORO.csv']['WIND_DIRECTION_LAGGED'])\n",
    "\n",
    "circular_corr = np.cos(direction_rad - lagged_direction_rad).mean()\n",
    "\n",
    "print(f\"Manual Circular Correlation: {circular_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c69ce",
   "metadata": {},
   "source": [
    "## Experimental\n",
    "Everything below this is highly experimental EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce361a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces for each trend component\n",
    "traces = []\n",
    "for i, trend in enumerate(trend_components):\n",
    "    trace = go.Scatter(\n",
    "        x=trend.index,\n",
    "        y=trend.values,\n",
    "        mode='lines',\n",
    "        name=f'Trend {i+1}'\n",
    "    )\n",
    "    traces.append(trace)\n",
    "\n",
    "# Create the layout for the plot\n",
    "layout = go.Layout(\n",
    "    title='Trend Lines Comparison',\n",
    "    xaxis=dict(title='Date'),\n",
    "    yaxis=dict(title='Temperature')\n",
    ")\n",
    "\n",
    "# Create the figure and plot the traces\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "# Display the interactive plot in the notebook (or in an HTML file)\n",
    "pyo.iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
